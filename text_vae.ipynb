{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "text_vae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThomKirwanEvans/VAE-Text-Generation/blob/master/text_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObENC1O0O0SY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0a1e5ba3-33f8-453c-effd-904b8cab925d"
      },
      "source": [
        "#%tensorflow_version 1.x\n",
        "from keras.layers import Bidirectional, Dense, Embedding, Input, Lambda, LSTM, RepeatVector, TimeDistributed, Layer, Activation, Dropout\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers.advanced_activations import ELU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from scipy import spatial\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import codecs\n",
        "import csv\n",
        "import os\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_hub as hub\n",
        "import random\n",
        "print('TF Version:',tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TF Version: 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlLng2nDQHW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "2f9bde8a-c7eb-4392-e237-3c507d9c041d"
      },
      "source": [
        "# Get data and embeddings\n",
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "# quora questions csv\n",
        "file_id = '10ofgOry0gPf62_6DHPAoQOohpCgbJAJJ'\n",
        "destination = '/content/quora_train.csv'\n",
        "if not os.path.exists(destination):\n",
        "  print('Downloading Quora questions')\n",
        "  download_file_from_google_drive(file_id, destination)\n",
        "# quora questions text\n",
        "file_id = '1O-e67fwHCeGvUn-QsrwgadtaEAV8nwLP'\n",
        "destination = '/content/quora_train.txt'\n",
        "if not os.path.exists(destination):\n",
        "  print('Downloading Quora questions')\n",
        "  download_file_from_google_drive(file_id, destination)\n",
        "# quora + lyrics\n",
        "file_id = '1UC8o_uk7QEuMHiJiOc-t1alYzbpUuBwz'\n",
        "destination = '/content/quora_lyrics.txt'\n",
        "if not os.path.exists(destination):\n",
        "  print('Downloading quora + lyrics')\n",
        "  download_file_from_google_drive(file_id, destination)\n",
        "# lyrics only\n",
        "file_id = '1rsXc0QSCmdsSxy-symKy3u05NL0ffXj8'\n",
        "destination = '/content/lyrics.txt'\n",
        "if not os.path.exists(destination):\n",
        "  print('Downloading Kaggle lyrics')\n",
        "  download_file_from_google_drive(file_id, destination)\n",
        "  \n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Quora questions\n",
            "Downloading Quora questions\n",
            "Downloading quora + lyrics\n",
            "Downloading Kaggle lyrics\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R_o6AKSO0Sd",
        "colab_type": "text"
      },
      "source": [
        "### Directories and text loading\n",
        "Initially we will set the main directories and some variables regarding the characteristics of our texts.\n",
        "We set the maximum sequence length to 15, the maximun number of words in our vocabulary to 12000 and we will use 50-dimensional embeddings. Finally we load our texts from a csv. The text file is the train file of the Quora Kaggle challenge containing around 808000 sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8fsJLNvO0Sd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "51d7ba50-7ff7-4650-8b8e-6491c288cb20"
      },
      "source": [
        "LOAD = True\n",
        "DOWNLOAD_MODEL = 'GLOVE_QUORA'\n",
        "BASE_DIR = '/content/'\n",
        "TRAIN_FILE = 'quora_train.csv'#'train_micro.csv'\n",
        "#TRAIN_FILE = 'lyrics.txt'\n",
        "TRAIN_DATA_FILE = BASE_DIR + TRAIN_FILE\n",
        "VALIDATION_SPLIT = 0.01\n",
        "MAX_SEQUENCE_LENGTH = 15\n",
        "MAX_NB_WORDS = 12000\n",
        "embedding_model = 'GLOVE50'\n",
        "\n",
        "\n",
        "\n",
        "if embedding_model == 'GLOVE50':\n",
        "  EMBEDDING_DIM = 50\n",
        "  GLOVE_EMBEDDING = BASE_DIR + 'glove.6B.50d.txt'\n",
        "  EMBED = 'GLOVE'\n",
        "  if not os.path.exists('/content/glove.6b.zip'):\n",
        "    print('Downloading GLOVE embeddings')\n",
        "    #url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "    #r = requests.get(url)\n",
        "    #with open('/content/glove.6b.zip', 'wb') as f:\n",
        "    #    f.write(r.content)\n",
        "    #import zipfile\n",
        "    #with zipfile.ZipFile('/content/glove.6b.zip', 'r') as zip_ref:\n",
        "    #    zip_ref.extractall('/content/')\n",
        "\n",
        "    file_id = '1aROAqwsrEqRDE7Yk0a2lcrNrflDS1Akc'\n",
        "    destination = '/content/glove.6B.50d.txt'\n",
        "    if not os.path.exists(destination):\n",
        "      print('Downloading Kaggle lyrics')\n",
        "      download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "    print('GLOVE ready')\n",
        "elif embedding_model == 'SWIVEL':\n",
        "  embed = hub.load(\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1\")\n",
        "  EMBED = 'HUB'\n",
        "  EMBEDDING_DIM = embed(['test']).numpy().size\n",
        "elif embedding_model == 'USE':\n",
        "  embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "  EMBED = 'HUB'\n",
        "  EMBEDDING_DIM = embed(['test']).numpy().size\n",
        "\n",
        "\n",
        "if TRAIN_FILE == 'quora_train.csv':\n",
        "  texts = [] \n",
        "  with open(TRAIN_DATA_FILE, 'r', encoding='utf-8') as f:\n",
        "      reader = csv.reader(f, delimiter=',')\n",
        "      header = next(reader)\n",
        "      for values in reader:\n",
        "          texts.append(values[3])\n",
        "          texts.append(values[4])\n",
        "\n",
        "else:\n",
        "  with open(TRAIN_DATA_FILE,'r',encoding='utf-8') as infile:\n",
        "    texts = infile.readlines()\n",
        "print('Found %s texts' % len(texts))\n",
        "  \n",
        "\n",
        "# everyday I'm shuffling\n",
        "\n",
        "random.shuffle(texts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading GLOVE embeddings\n",
            "GLOVE ready\n",
            "Found 808580 texts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_x-GMD2XKpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test hub model instead\n",
        "\n",
        "#USE = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "#SWIVEL = hub.load(\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1\")\n",
        "#W2V = hub.load(\"https://tfhub.dev/google/Wiki-words-250/2\")\n",
        "#NNLM = hub.load(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n",
        "#NNLM50 = hub.Module(\"https://tfhub.dev/google/random-nnlm-en-dim50/1\")\n",
        "\n",
        "#print(SWIVEL(['test']).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj3o4_QMO0Sh",
        "colab_type": "text"
      },
      "source": [
        "### Text Preprocessing\n",
        "To preprocess the text we will use the tokenizer and the text_to_sequences function from Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZJI4urZO0Sh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "1a5a8b18-f49a-4ef0-8971-77b41b2d806d"
      },
      "source": [
        "tokenizer = Tokenizer(MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "word_index = tokenizer.word_index #the dict values start from 1 so this is fine with zeropadding\n",
        "index2word = {v: k for k, v in word_index.items()}\n",
        "print('Found %s unique tokens' % len(word_index))\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "data_1 = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Initial shape of data tensor:', data_1.shape)\n",
        "NB_WORDS = (min(tokenizer.num_words, len(word_index)) + 1 ) #+1 for zero padding\n",
        "print('Found',NB_WORDS,'words')\n",
        "\n",
        "\n",
        "\n",
        "# trim data to the nearest 100 samples\n",
        "n_texts = len(texts)\n",
        "n_trim = int(np.floor(n_texts/100)*100)\n",
        "print('Trimming to',n_trim)\n",
        "data_1 = data_1[:n_trim]\n",
        "\n",
        "\n",
        "n_texts = len(data_1)\n",
        "val_pct = VALIDATION_SPLIT\n",
        "val_num = int(np.ceil(n_texts*val_pct/100)*100)\n",
        "val_from = n_texts - val_num\n",
        "\n",
        "\n",
        "data_1_val = data_1[val_from:]\n",
        "data_1 = data_1[:val_from] \n",
        "print('Shape of train tensor:', data_1.shape)\n",
        "print('Shape of val tensor:', data_1_val.shape)\n",
        "n_train = data_1.shape[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 95596 unique tokens\n",
            "Initial shape of data tensor: (808580, 15)\n",
            "Found 12001 words\n",
            "Trimming to 808500\n",
            "Shape of train tensor: (800400, 15)\n",
            "Shape of val tensor: (8100, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTEeJWlLNUwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c3d720eb-c7e1-47d3-870c-ebcc2e033f49"
      },
      "source": [
        "# check that data doesn't just have a load of nulls\n",
        "print(data_1)\n",
        "print(texts)\n",
        "print(tokenizer.texts_to_sequences(texts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkUWuZZXOct-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "7c2ee4f4-5903-457e-86bb-24c0edd73e4d"
      },
      "source": [
        "# Let's check the sequence length\n",
        "from matplotlib import pyplot as plt\n",
        "line_len = [len(x) for x in texts]\n",
        "plt.hist(np.array(line_len),20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4.95778e+05, 2.60437e+05, 4.68380e+04, 3.86700e+03, 1.29400e+03,\n",
              "        2.91000e+02, 2.70000e+01, 1.20000e+01, 6.00000e+00, 6.00000e+00,\n",
              "        5.00000e+00, 0.00000e+00, 2.00000e+00, 0.00000e+00, 1.00000e+00,\n",
              "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.60000e+01]),\n",
              " array([   0.  ,   58.45,  116.9 ,  175.35,  233.8 ,  292.25,  350.7 ,\n",
              "         409.15,  467.6 ,  526.05,  584.5 ,  642.95,  701.4 ,  759.85,\n",
              "         818.3 ,  876.75,  935.2 ,  993.65, 1052.1 , 1110.55, 1169.  ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dmbxWujO0Sm",
        "colab_type": "text"
      },
      "source": [
        "### Sentence generator\n",
        "In order to reduce the memory requirements we will gradually read our sentences from the csv through Pandas as we feed them to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA6PBOBTO0Sm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "62044420-83be-4c75-a84f-374b4f40fa7b"
      },
      "source": [
        "\n",
        "if TRAIN_FILE == 'quora_train.csv':\n",
        "  def sent_generator_file(TRAIN_DATA_FILE, chunksize):\n",
        "      reader = pd.read_csv(TRAIN_DATA_FILE, chunksize=chunksize, iterator=True)\n",
        "      for df in reader:\n",
        "          #print(df.shape)\n",
        "          #df=pd.read_csv(TRAIN_DATA_FILE, iterator=False)\n",
        "          val3 = df.iloc[:,3:4].values.tolist()\n",
        "          val4 = df.iloc[:,4:5].values.tolist()\n",
        "          flat3 = [item for sublist in val3 for item in sublist]\n",
        "          flat4 = [str(item) for sublist in val4 for item in sublist]\n",
        "          texts = [] \n",
        "          texts.extend(flat3[:])\n",
        "          texts.extend(flat4[:])\n",
        "          \n",
        "          sequences = tokenizer.texts_to_sequences(texts)\n",
        "          data_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "          yield [data_train, data_train]\n",
        "else:\n",
        "  def sent_generator_file(TRAIN_DATA_FILE, chunksize):\n",
        "      reader = pd.read_csv(TRAIN_DATA_FILE, chunksize=chunksize, iterator=True, delimiter='\\n')\n",
        "      for df in reader:\n",
        "          texts = df.values.tolist()\n",
        "          texts = [x[0] for x in texts]\n",
        "          sequences = tokenizer.texts_to_sequences(texts)\n",
        "          data_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "          yield [data_train, data_train]\n",
        "\n",
        "def sent_generator(data, chunksize):\n",
        "  start = 0\n",
        "  end = start+chunksize\n",
        "  n = data.shape[0]\n",
        "  while end <= n:\n",
        "    _data = data[start:end,:]    \n",
        "    start = end\n",
        "    end = start+chunksize\n",
        "    yield[_data,_data]\n",
        "\n",
        "# the last batch should be the same size as the first, else we'll have errors later\n",
        "sgen = sent_generator(data_1,100)\n",
        "count = 0\n",
        "for d in sgen:\n",
        "  count += 1\n",
        "  pass\n",
        "print(d[0].shape)\n",
        "print(data_1.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 15)\n",
            "(800400, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDIBE94aO0Sq",
        "colab_type": "text"
      },
      "source": [
        "### Word embeddings\n",
        "We will use pretrained Glove word embeddings as embeddings for our network. We create a matrix with one embedding for every word in our vocabulary and then we will pass this matrix as weights to the keras embedding layer of our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuRjcttVO0Sq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2f32b5eb-7966-467d-e806-ceaecaab3b31"
      },
      "source": [
        "if EMBED == 'GLOVE':\n",
        "  embeddings_index = {}\n",
        "  f = open(GLOVE_EMBEDDING, encoding='utf8')\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "  f.close()\n",
        "elif EMBED == 'HUB':\n",
        "  print('Calculating individual word embeddings - batch to speed up')\n",
        "  embeddings_index = {}\n",
        "  embeddings_index['unk'] = embed(['unknown']).numpy()\n",
        "\n",
        "print('Found %s precached word vectors.' % len(embeddings_index))\n",
        "\n",
        "glove_embedding_matrix = np.zeros((NB_WORDS, EMBEDDING_DIM))\n",
        "unknown_count = 0\n",
        "for word, i in word_index.items():\n",
        "    if i < NB_WORDS:\n",
        "        if EMBED == 'GLOVE':\n",
        "          embedding_vector = embeddings_index.get(word)\n",
        "        elif EMBED == 'HUB':\n",
        "          embedding_vector = embed([word]).numpy()\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be the word embedding of 'unk'.\n",
        "            glove_embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            glove_embedding_matrix[i] = embeddings_index.get('unk')\n",
        "            unknown_count += 1\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(glove_embedding_matrix, axis=1) == 0))\n",
        "print('Unknown count:',unknown_count)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 precached word vectors.\n",
            "Null word embeddings: 1\n",
            "Unknown count: 374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBv5zaxqL79G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "fe968552-06ec-4dff-ae75-c76afcf8c82b"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.scatter(glove_embedding_matrix[:,0],glove_embedding_matrix[:,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc2ea840978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtLk91eLO0St",
        "colab_type": "text"
      },
      "source": [
        "### VAE model\n",
        "Our model is based on a seq2seq architecture with a bidirectional LSTM encoder and an LSTM decoder and ELU activations.\n",
        "We feed the latent representation at every timestep as input to the decoder through \"RepeatVector(max_len)\".\n",
        "To avoid the one-hot representation of labels we use the \"tf.contrib.seq2seq.sequence_loss\" that requires as labels only the word indexes (the same that go in input to the embedding matrix) and calculates internally the final softmax (so the model ends with a dense layer with linear activation). Optionally the \"sequence_loss\" allows to use the sampled softmax which helps when dealing with large vocabularies (for example with a 50k words vocabulary) but in this I didn't use it.\n",
        "Moreover, due to the pandas iterator that reads the csv both the train size and validation size must be divisible by the batch_size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-K3chNoO0Su",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "a3f065e3-26aa-4b7b-954c-f2a7c1ca9d8f"
      },
      "source": [
        "batch_size = 100\n",
        "max_len = MAX_SEQUENCE_LENGTH\n",
        "emb_dim = EMBEDDING_DIM\n",
        "latent_dim = 32\n",
        "intermediate_dim = 96\n",
        "epsilon_std = 1.0\n",
        "num_sampled=500\n",
        "act = ELU()\n",
        "\n",
        "#y = Input(batch_shape=(None, max_len, NB_WORDS))\n",
        "x = Input(batch_shape=(None, max_len))\n",
        "x_embed = Embedding(NB_WORDS, emb_dim, weights=[glove_embedding_matrix],\n",
        "                            input_length=max_len, trainable=False)(x)\n",
        "h = Bidirectional(LSTM(intermediate_dim, return_sequences=False, recurrent_dropout=0.2), merge_mode='concat')(x_embed)\n",
        "#h = Bidirectional(LSTM(intermediate_dim, return_sequences=False), merge_mode='concat')(h)\n",
        "h = Dropout(0.2)(h)\n",
        "h = Dense(intermediate_dim, activation='linear')(h)\n",
        "h = act(h)\n",
        "h = Dropout(0.2)(h)\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_var = Dense(latent_dim)(h)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
        "                              stddev=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# we instantiate these layers separately so as to reuse them later\n",
        "repeated_context = RepeatVector(max_len)\n",
        "decoder_h = LSTM(intermediate_dim, return_sequences=True, recurrent_dropout=0.2)\n",
        "decoder_mean = TimeDistributed(Dense(NB_WORDS, activation='linear'))#softmax is applied in the seq2seqloss by tf\n",
        "h_decoded = decoder_h(repeated_context(z))\n",
        "x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "\n",
        "# placeholder loss\n",
        "def zero_loss(y_true, y_pred):\n",
        "    return K.zeros_like(y_pred)\n",
        "\n",
        "#=========================== Necessary only if you want to use Sampled Softmax =======================#\n",
        "#Sampled softmax\n",
        "logits = tf.constant(np.random.randn(batch_size, max_len, NB_WORDS), tf.float32)\n",
        "targets = tf.constant(np.random.randint(NB_WORDS, size=(batch_size, max_len)), tf.int32)\n",
        "proj_w = tf.constant(np.random.randn(NB_WORDS, NB_WORDS), tf.float32)\n",
        "proj_b = tf.constant(np.zeros(NB_WORDS), tf.float32)\n",
        "\n",
        "def _sampled_loss(labels, logits):\n",
        "    labels = tf.cast(labels, tf.int64)\n",
        "    labels = tf.reshape(labels, [-1, 1])\n",
        "    logits = tf.cast(logits, tf.float32)\n",
        "    return tf.cast(\n",
        "                    tf.nn.sampled_softmax_loss(\n",
        "                        proj_w,\n",
        "                        proj_b,\n",
        "                        labels,\n",
        "                        logits,\n",
        "                        num_sampled=num_sampled,\n",
        "                        num_classes=NB_WORDS),\n",
        "                    tf.float32)\n",
        "softmax_loss_f = _sampled_loss\n",
        "#====================================================================================================#\n",
        "\n",
        "# Custom VAE loss layer\n",
        "class CustomVariationalLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.is_placeholder = True\n",
        "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
        "        self.target_weights = tf.constant(np.ones((batch_size, max_len)), tf.float32)\n",
        "\n",
        "    def vae_loss(self, x, x_decoded_mean):\n",
        "        #xent_loss = K.sum(metrics.categorical_crossentropy(x, x_decoded_mean), axis=-1)\n",
        "        labels = tf.cast(x, tf.int32)\n",
        "        xent_loss = K.sum(tfa.seq2seq.sequence_loss(x_decoded_mean, labels, \n",
        "                                                     weights=self.target_weights,\n",
        "                                                     average_across_timesteps=False,\n",
        "                                                     average_across_batch=False), axis=-1)\n",
        "                                                     #softmax_loss_function=softmax_loss_f), axis=-1)#, uncomment for sampled doftmax\n",
        "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "        return K.mean(xent_loss + kl_loss)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs[0]\n",
        "        x_decoded_mean = inputs[1]\n",
        "        print(x.shape, x_decoded_mean.shape)\n",
        "        loss = self.vae_loss(x, x_decoded_mean)\n",
        "        self.add_loss(loss, inputs=inputs)\n",
        "        # we don't use this output, but it has to have the correct shape:\n",
        "        return K.ones_like(x)\n",
        "\n",
        "loss_layer = CustomVariationalLayer()([x, x_decoded_mean])\n",
        "vae = Model(x, [loss_layer])\n",
        "opt = Adam(lr=0.01) #SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "vae.compile(optimizer='adam', loss=[zero_loss])\n",
        "vae.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15) (100, 15, 12001)\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 15)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 15, 50)       600050      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 192)          112896      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 192)          0           bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 96)           18528       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "elu_2 (ELU)                     (None, 96)           0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 96)           0           elu_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 32)           3104        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 32)           3104        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 32)           0           dense_6[0][0]                    \n",
            "                                                                 dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_2 (RepeatVector)  (None, 15, 32)       0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, 15, 96)       49536       repeat_vector_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 15, 12001)    1164097     lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "custom_variational_layer_2 (Cus [(None, 15), (None,  0           input_2[0][0]                    \n",
            "                                                                 time_distributed_2[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 1,951,315\n",
            "Trainable params: 1,351,265\n",
            "Non-trainable params: 600,050\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Na3xUqn2hj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8575b2b3-0499-4169-be1a-4c3e0583ccd7"
      },
      "source": [
        "if len(DOWNLOAD_MODEL)>0:\n",
        "  print('Downloading model',DOWNLOAD_MODEL)\n",
        "  if DOWNLOAD_MODEL == 'GLOVE_QUORA':    \n",
        "    file_id = '1pE1XOueOayigOiatY67ysTx0L_K4PbMnP'\n",
        "\n",
        "  destination = '/content/models/vae_seq2seq.h5'\n",
        "  if not os.path.exists('/content/models/'):\n",
        "    os.mkdir('/content/models/')\n",
        "  if not os.path.exists(destination):      \n",
        "    download_file_from_google_drive(file_id, destination)\n",
        "  else:\n",
        "    print('Model exists; delete if you want to download')\n",
        "    1/0\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading model GLOVE_QUORA\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VArie2tD-KJW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "7f3c36a4-2435-4720-b162-d1033176ba8b"
      },
      "source": [
        "# load the existing model if there is one\n",
        "if LOAD and os.path.exists('/content/models/vae_seq2seq.h5'):\n",
        "  vae.load_weights('/content/models/vae_seq2seq.h5')\n",
        "  print('Loaded weights')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ac69ac1ab06a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the existing model if there is one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mLOAD\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/models/vae_seq2seq.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/models/vae_seq2seq.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5IIBPpXO0Sy",
        "colab_type": "text"
      },
      "source": [
        "### Model training\n",
        "We train our model for 100 epochs through keras \".fit_generator\". The number of steps per epoch is equal to the number of sentences that we have in the train set (800000) divided by the batch size; the additional /2 is due to the fact that our csv has two sentnces per line so in the end we have to read with our generator only 400000 lines per epoch.\n",
        "For validation data we pass the same array twice since input and labels of this model are the same. \n",
        "If we didn't use the \"tf.contrib.seq2seq.sequence_loss\" (or another similar function) we would have had to pass as labels the sequence of word one-hot encodings with dimension (batch_size, seq_len, vocab_size) consuming a lot of memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0hiuP-hO0Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_checkpoint(dir, model_name):\n",
        "    filepath = dir + '/' + model_name + \".h5\" #-{epoch:02d}-{decoded_mean:.2f}\n",
        "    directory = os.path.dirname(filepath)\n",
        "    try:\n",
        "        os.stat(directory)\n",
        "    except:\n",
        "        os.mkdir(directory)\n",
        "    checkpointer = ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=False)\n",
        "    return checkpointer\n",
        "\n",
        "checkpointer = create_model_checkpoint('models', 'vae_seq2seq')\n",
        "\n",
        "max_sent = 1000\n",
        "nb_epoch = 100\n",
        "n_steps = round(n_train/batch_size/2) #we use the first 800000\n",
        "print(n_steps,'steps per epoch')\n",
        "vocabulary = []\n",
        "for counter in range(nb_epoch):\n",
        "    # everytime we're shuffling\n",
        "    np.random.shuffle(data_1)\n",
        "    np.random.shuffle(data_1_val)\n",
        "    print('-------epoch: ',counter,'--------')\n",
        "    vae.fit_generator(sent_generator(data_1, batch_size),\n",
        "                          steps_per_epoch=n_steps, epochs=1, callbacks=[checkpointer],\n",
        "                          validation_data=(data_1_val, data_1_val))\n",
        "    \n",
        "    \n",
        "    # predict new words\n",
        "    # build a model to project sentences on the latent space\n",
        "    encoder = Model(x, z_mean)\n",
        "\n",
        "    # build a generator that can sample sentences from the learned distribution\n",
        "    decoder_input = Input(shape=(latent_dim,))\n",
        "    _h_decoded = decoder_h(repeated_context(decoder_input))\n",
        "    _x_decoded_mean = decoder_mean(_h_decoded)\n",
        "    _x_decoded_mean = Activation('softmax')(_x_decoded_mean)\n",
        "    generator = Model(decoder_input, _x_decoded_mean)\n",
        "\n",
        "    index2word = {v: k for k, v in word_index.items()}\n",
        "    sent_encoded = encoder.predict(data_1_val[:max_sent,:], batch_size = 16)\n",
        "    x_test_reconstructed = generator.predict(sent_encoded)\n",
        "    original_words = []\n",
        "    predicted_words = []\n",
        "                                            \n",
        "    for sent_idx in range(max_sent):\n",
        "      reconstructed_indexes = np.apply_along_axis(np.argmax, 1, x_test_reconstructed[sent_idx])\n",
        "      #np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx])\n",
        "      #np.max(np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx]))\n",
        "      word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
        "      word_list = ['' if x==None else x for x in word_list]\n",
        "      original_sent = list(np.vectorize(index2word.get)(data_1_val[sent_idx]))\n",
        "      original_sent = ['' if x==None else x for x in original_sent]\n",
        "      original_words += original_sent\n",
        "      predicted_words += word_list\n",
        "    ow = len(set(original_words))\n",
        "    pw = len(set(predicted_words))\n",
        "    tw = len(original_words)\n",
        "    vocabulary = set(list(vocabulary) + list(set(predicted_words)))\n",
        "    vw = len(vocabulary)\n",
        "    print('Predicting',pw,'/',ow,'unique words in validation set (',vw,'word vocabulary )')\n",
        "    print('Target sentence:',' '.join(original_sent))\n",
        "    print('Predicted sentence:',' '.join(word_list))\n",
        "\n",
        "vae.save('models/vae_finished.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pDjrjHhO0S4",
        "colab_type": "text"
      },
      "source": [
        "### Project and sample sentences from the latent space\n",
        "Now we build an encoder model model that takes a sentence and projects it on the latent space and a decoder model that goes from the latent space back to the text representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NflOfCFaO0S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build a model to project sentences on the latent space\n",
        "encoder = Model(x, z_mean)\n",
        "\n",
        "# build a generator that can sample sentences from the learned distribution\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "_h_decoded = decoder_h(repeated_context(decoder_input))\n",
        "_x_decoded_mean = decoder_mean(_h_decoded)\n",
        "_x_decoded_mean = Activation('softmax')(_x_decoded_mean)\n",
        "generator = Model(decoder_input, _x_decoded_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuxJtfMiO0S7",
        "colab_type": "text"
      },
      "source": [
        "### Test on validation sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7SsQ4TpO0S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_sent = 1500\n",
        "index2word = {v: k for k, v in word_index.items()}\n",
        "sent_encoded = encoder.predict(data_1_val[:max_sent,:], batch_size = 16)\n",
        "x_test_reconstructed = generator.predict(sent_encoded)\n",
        "original_words = []\n",
        "predicted_words = []\n",
        "                                         \n",
        "for sent_idx in range(10):\n",
        "  reconstructed_indexes = np.apply_along_axis(np.argmax, 1, x_test_reconstructed[sent_idx])\n",
        "  #np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx])\n",
        "  #np.max(np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx]))\n",
        "  word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
        "  word_list = ['' if x==None else x for x in word_list]\n",
        "  print('Word list:',' '.join(word_list))\n",
        "  original_sent = list(np.vectorize(index2word.get)(data_1_val[sent_idx]))\n",
        "  original_sent = ['' if x==None else x for x in original_sent]\n",
        "  print('Original sentence:',' '.join(original_sent))\n",
        "\n",
        "  original_words += original_sent\n",
        "  predicted_words += word_list\n",
        "ow = len(set(original_words))\n",
        "pw = len(set(predicted_words))\n",
        "print('Predicting',pw,'/',ow,'unique words')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF7VZpuY8k0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(reconstructed_indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JH_0mFTO0S-",
        "colab_type": "text"
      },
      "source": [
        "### Sentence processing and interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm55WnnXO0S_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to parse a sentence\n",
        "def sent_parse(sentence, mat_shape):\n",
        "    sequence = tokenizer.texts_to_sequences(sentence)\n",
        "    padded_sent = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    return padded_sent#[padded_sent, sent_one_hot]\n",
        "\n",
        "# input: encoded sentence vector\n",
        "# output: encoded sentence vector in dataset with highest cosine similarity\n",
        "def find_similar_encoding(sent_vect):\n",
        "    all_cosine = []\n",
        "    for sent in sent_encoded:\n",
        "        result = 1 - spatial.distance.cosine(sent_vect, sent)\n",
        "        all_cosine.append(result)\n",
        "    data_array = np.array(all_cosine)\n",
        "    maximum = data_array.argsort()[-3:][::-1][1]\n",
        "    new_vec = sent_encoded[maximum]\n",
        "    return new_vec\n",
        "\n",
        "# input: two points, integer n\n",
        "# output: n equidistant points on the line between the input points (inclusive)\n",
        "def shortest_homology(point_one, point_two, num):\n",
        "    dist_vec = point_two - point_one\n",
        "    sample = np.linspace(0, 1, num, endpoint = True)\n",
        "    hom_sample = []\n",
        "    for s in sample:\n",
        "        hom_sample.append(point_one + s * dist_vec)\n",
        "    return hom_sample\n",
        "\n",
        "# input: original dimension sentence vector\n",
        "# output: sentence text\n",
        "def print_latent_sentence(sent_vect):\n",
        "    sent_vect = np.reshape(sent_vect,[1,latent_dim])\n",
        "    sent_reconstructed = generator.predict(sent_vect)\n",
        "    sent_reconstructed = np.reshape(sent_reconstructed,[max_len,NB_WORDS])\n",
        "    reconstructed_indexes = np.apply_along_axis(np.argmax, 1, sent_reconstructed)\n",
        "    np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx])\n",
        "    np.max(np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx]))\n",
        "    word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
        "    w_list = [w for w in word_list if w]\n",
        "    print(' '.join(w_list))\n",
        "    #print(word_list)\n",
        "        \n",
        "def new_sents_interp(sent1, sent2, n):\n",
        "    tok_sent1 = sent_parse(sent1, [15])\n",
        "    tok_sent2 = sent_parse(sent2, [15])\n",
        "    enc_sent1 = encoder.predict(tok_sent1, batch_size = 16)\n",
        "    enc_sent2 = encoder.predict(tok_sent2, batch_size = 16)\n",
        "    test_hom = shortest_homology(enc_sent1, enc_sent2, n)\n",
        "    for point in test_hom:\n",
        "        print_latent_sentence(point)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVgEK8K9O0TC",
        "colab_type": "text"
      },
      "source": [
        "### Example\n",
        "Now we can try to parse two sentences and interpolate between them generating new sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83NjNlzYO0TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence1=['where can i find a book on machine learning']\n",
        "print('From:',sentence1)\n",
        "mysent = sent_parse(sentence1, [15])\n",
        "mysent_encoded = encoder.predict(mysent, batch_size = 16)\n",
        "print_latent_sentence(mysent_encoded)\n",
        "print_latent_sentence(find_similar_encoding(mysent_encoded))\n",
        "\n",
        "sentence2=['how can i become a successful entrepreneur']\n",
        "mysent2 = sent_parse(sentence2, [15])\n",
        "mysent_encoded2 = encoder.predict(mysent2, batch_size = 16)\n",
        "print_latent_sentence(mysent_encoded2)\n",
        "print_latent_sentence(find_similar_encoding(mysent_encoded2))\n",
        "print('-----------------')\n",
        "\n",
        "new_sents_interp(sentence1, sentence2, 6)\n",
        "print('To:',sentence2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E04zL-InO0TG",
        "colab_type": "text"
      },
      "source": [
        "### Results\n",
        "After training with these parameters for 100 epochs I got these results from interpolating between these two sentences:\n",
        "\n",
        "sentence1=['where can i find a book on machine learning']\n",
        "sentence2=['how can i become a successful entrepreneur']\n",
        "\n",
        "Generated sentences:\n",
        "- ------------------------------------------- -\n",
        "-  where can i find a book on machine learning\n",
        "-  where can i find a a machine book\n",
        "-  how can i write a a machine book\n",
        "-  how can i become a successful architect\n",
        "-  how can i become a successful architect\n",
        "-  how can i become a successful entrepreneur\n",
        "- ------------------------------------------- -\n",
        "\n",
        "As we can see the results are not yet completely satisfying because not all the sentences are grammatically correct and in the interpolation the same sentence has been generated multiple times but anyway the model, even in this preliminary version seems to start working.\n",
        "There are certainly many improvements that could be done like:\n",
        "-  removing all the sentences longer than 15 instead of just truncating them\n",
        "-  introduce the equivalent of word dropout used in the original paper for this decoder architecture \n",
        "-  parameter tuning (this model trains in few hours on a GTX950M with 2GB memory so it's definitely possible to try larger nets)\n",
        "-  Using word embeddings with higher dimensionality\n",
        "-  train on a more general dataset (Quora sentences are all questions)\n",
        "\n",
        "Stay tuned for future refinings of the model!"
      ]
    }
  ]
}